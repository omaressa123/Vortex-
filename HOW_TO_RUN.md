# ğŸš€ How to Run the AI-Powered Data Cleaning & Dashboard System

## **Option 1: Flask Dashboard (Recommended)**

### **Step 1: Install Dependencies**
```bash
pip install -r requirements.txt
```

### **Step 2: Run Flask App**
```bash
python app.py
```

### **Step 3: Access Dashboard**
- **Main App**: http://127.0.0.1:8000
- **Dashboard**: http://127.0.0.1:8000/dashboard/

---

## **Option 2: Streamlit Dashboard (Original)**

### **Step 1: Run Streamlit**
```bash
streamlit run dashboard/app.py
```

### **Step 2: Access Dashboard**
- **Streamlit**: http://localhost:8501

---

## **ğŸ”¹ Local LLM Setup (Optional - No API Keys!)**

### **Install Ollama**
```bash
# Windows: Download from https://ollama.ai/download
# Mac: brew install ollama
# Linux: curl -fsSL https://ollama.ai/install.sh | sh
```

### **Start Ollama**
```bash
ollama serve
```

### **Pull Models**
```bash
ollama pull llama3          # Recommended
ollama pull mistral         # Fast
ollama pull phi-3           # Lightweight
```

### **Use in Dashboard**
1. Go to http://127.0.0.1:8000/dashboard/
2. Select "Local LLM (Ollama)"
3. Choose your model
4. No API keys needed!

---

## **ğŸ”‘ Cloud API Setup (Optional)**

### **Set Environment Variables**
```bash
# OpenAI
export OPENAI_API_KEY="sk-your-key-here"

# DeepSeek (RapidAPI)
export DEEPSEEK_API_KEY="your-key-here"

# Anthropic
export ANTHROPIC_API_KEY="sk-ant-your-key-here"

# Google Gemini
export GOOGLE_API_KEY="your-key-here"
```

### **Or Copy Configuration File**
```bash
cp api_keys.env.example .env
# Edit .env with your actual API keys
```

---

## **ğŸ“ Project Structure**

```
ğŸ“¦ AI-Powered Data Cleaning, Analysis & Dashboard System
â”œâ”€â”€ ğŸš€ app.py                    # Main Flask application
â”œâ”€â”€ ğŸ“Š dashboard/
â”‚   â”œâ”€â”€ ğŸ“ˆ flask_dashboard.py     # Flask dashboard blueprint
â”‚   â””â”€â”€ ğŸ“‹ app.py               # Original Streamlit app
â”œâ”€â”€ ğŸ§  rag/
â”‚   â””â”€â”€ ğŸ¤– rag_engine.py         # RAG system with local/cloud support
â”œâ”€â”€ ğŸ”§ utils/
â”‚   â”œâ”€â”€ ğŸ¦™ local_llm.py          # Local LLM (Ollama) integration
â”‚   â””â”€â”€ ğŸŒ deepseek_llm.py       # DeepSeek API integration
â”œâ”€â”€ ğŸ¨ templates/
â”‚   â””â”€â”€ ğŸ“„ dashboard_main.html   # Dashboard UI
â”œâ”€â”€ ğŸ’» static/
â”‚   â”œâ”€â”€ ğŸ¯ dashboard_main.js     # Dashboard JavaScript
â”‚   â””â”€â”€ ğŸ¨ style.css            # Styling
â””â”€â”€ ğŸ“š rag/knowledge_base/       # RAG knowledge base
```

---

## **ğŸ¯ Features Available**

### **Flask Dashboard Features**
- âœ… **Data Upload & Preview**
- âœ… **Data Profiling & Quality Analysis**
- âœ… **Data Cleaning with AI**
- âœ… **Exploratory Data Analysis (EDA)**
- âœ… **Data Visualization**
- âœ… **AI-Powered Insights**
- âœ… **Conversational RAG Q&A**
- âœ… **Multiple Dashboard Templates**
- âœ… **Local LLM Support (Ollama)**
- âœ… **Cloud API Support (OpenAI, DeepSeek, Anthropic, Google)**
- âœ… **User Authentication**

### **Local LLM Benefits**
- ğŸ”’ **100% Privacy** - Data never leaves your computer
- ğŸ’° **No Costs** - No API usage fees
- ğŸš€ **Fast Response** - No network latency
- ğŸ›ï¸ **Full Control** - Your models, your rules

### **Cloud API Benefits**
- ğŸŒ **More Powerful Models**
- ğŸ“ˆ **Higher Accuracy**
- ğŸ”§ **Easy Setup** - Just add API key

---

## **ğŸ› Troubleshooting**

### **Common Issues**

#### **1. Import Errors**
```bash
# Install missing packages
pip install langchain-community sentence-transformers requests
```

#### **2. Local LLM Not Working**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama
ollama serve
```

#### **3. Port Already in Use**
```bash
# Kill existing process
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Or use different port
python app.py --port 8001
```

#### **4. API Key Issues**
- Check environment variables are set
- Verify API key format
- Test API key in dashboard

---

## **ğŸ¨ Dashboard Usage**

### **1. Upload Data**
- Supported formats: CSV, Excel, JSON
- Click "Upload & Generate Dashboard"

### **2. Configure AI**
- **Local LLM**: Select "Local LLM (Ollama)" â†’ Choose model
- **Cloud API**: Select provider â†’ Enter API key â†’ Test

### **3. Analyze Data**
- **Profile**: Data quality analysis
- **Clean**: AI-powered data cleaning
- **EDA**: Exploratory data analysis
- **Visualize**: Charts and graphs
- **Insights**: AI-generated insights
- **Q&A**: Ask questions about your data

### **4. Customize**
- **Themes**: 6 color themes
- **Templates**: Multiple dashboard layouts
- **Export**: Download results

---

## **ğŸš€ Production Deployment**

### **Docker (Recommended)**
```bash
docker build -t vortex-dashboard .
docker run -p 8000:8000 vortex-dashboard
```

### **Gunicorn**
```bash
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:8000 app:app
```

---

## **ğŸ“ Support**

### **Documentation**
- ğŸ“š **GitHub**: https://github.com/omaressa123/Vortex-
- ğŸ“– **Wiki**: Setup guides and tutorials

### **Issues**
- ğŸ› **Report**: Create GitHub issue
- ğŸ’¬ **Discuss**: GitHub discussions

---

**ğŸ‰ Your AI-Powered Data Dashboard is ready!**

**Start with**: `python app.py` â†’ **Visit**: http://127.0.0.1:8000
